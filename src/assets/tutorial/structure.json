[
    {
        "name": "t01_basic_usage.md",
        "displayName": " Tutorial 1: Getting started with FastEstimator",
        "toc": [
            {
                "name": "Tutorial 1: Getting started with FastEstimator",
                "displayName": "tutorial_1_getting_started_with_fastestimator"
            },
            {
                "name": "Step 1: Prepare the Pipeline",
                "displayName": "step_1_prepare_the_pipeline"
            },
            {
                "name": "Import training and validation data as numpy array for instance",
                "displayName": "import_training_and_validation_data_as_numpy_array_for_instance"
            },
            {
                "name": "Add one channel dimension for convolution later",
                "displayName": "add_one_channel_dimension_for_convolution_later"
            },
            {
                "name": "Create a dictionary to identify the training and evaluation data",
                "displayName": "create_a_dictionary_to_identify_the_training_and_evaluation_data"
            },
            {
                "name": "We specify for each x images and y label also in a dictionnary",
                "displayName": "we_specify_for_each_x_images_and_y_label_also_in_a_dictionnary"
            },
            {
                "name": "Creating the pipeline with the desired batchsize and preprocessing operation here Minmax",
                "displayName": "creating_the_pipeline_with_the_desired_batchsize_and_preprocessing_operation_here_minmax"
            },
            {
                "name": "Step 2: Define the network",
                "displayName": "step_2_define_the_network"
            },
            {
                "name": "We first define a model using FEModel to compile it",
                "displayName": "we_first_define_a_model_using_femodel_to_compile_it"
            },
            {
                "name": "We summarize all operations and loss in the Network",
                "displayName": "we_summarize_all_operations_and_loss_in_the_network"
            },
            {
                "name": "Step 3: Create the Estimator",
                "displayName": "step_3_create_the_estimator"
            },
            {
                "name": "We create the estimator and specify the number of epochs for training",
                "displayName": "we_create_the_estimator_and_specify_the_number_of_epochs_for_training"
            },
            {
                "name": "and train your model",
                "displayName": "and_train_your_model"
            }
        ]
    },
    {
        "name": "t02_using_data_in_disk.md",
        "displayName": " Tutorial 2: Dealing with large datasets with FastEstimator",
        "toc": [
            {
                "name": "Tutorial 2: Dealing with large datasets with FastEstimator",
                "displayName": "tutorial_2_dealing_with_large_datasets_with_fastestimator"
            },
            {
                "name": "Before we start:",
                "displayName": "before_we_start"
            },
            {
                "name": "Step 0: Get the paths to the csv files",
                "displayName": "step_0_get_the_paths_to_the_csv_files"
            },
            {
                "name": "Step 1: RecordWriter",
                "displayName": "step_1_recordwriter"
            },
            {
                "name": "We simply create a RecordWriter will all required arguments",
                "displayName": "we_simply_create_a_recordwriter_will_all_required_arguments"
            },
            {
                "name": "Step 2: Pipeline  Network  Estimator see tutorial 1 for details",
                "displayName": "step_2_pipeline__network__estimator_see_tutorial_1_for_details"
            },
            {
                "name": "Pipeline creation",
                "displayName": "pipeline_creation"
            },
            {
                "name": "Model and network definition",
                "displayName": "model_and_network_definition"
            },
            {
                "name": "Estimator definition",
                "displayName": "estimator_definition"
            },
            {
                "name": "Step 3: Start training",
                "displayName": "step_3_start_training"
            },
            {
                "name": "Launch the training",
                "displayName": "launch_the_training"
            },
            {
                "name": "Key takeaways:",
                "displayName": "key_takeaways"
            }
        ]
    },
    {
        "name": "t03_operator.md",
        "displayName": " Tutorial 3: Operator",
        "toc": [
            {
                "name": "Tutorial 3: Operator",
                "displayName": "tutorial_3_operator"
            },
            {
                "name": "How does Operator work",
                "displayName": "how_does_operator_work"
            },
            {
                "name": "How to express Operator connections in FastEstimator",
                "displayName": "how_to_express_operator_connections_in_fastestimator"
            },
            {
                "name": "What different types of Operators are there",
                "displayName": "what_different_types_of_operators_are_there"
            },
            {
                "name": "How is an Operator defined",
                "displayName": "how_is_an_operator_defined"
            },
            {
                "name": "Operator demo in FastEstimator",
                "displayName": "operator_demo_in_fastestimator"
            },
            {
                "name": "Import libraries",
                "displayName": "import_libraries"
            },
            {
                "name": "Download data in a temporary repository using loaddata",
                "displayName": "download_data_in_a_temporary_repository_using_loaddata"
            },
            {
                "name": "Step 0: Use prebuilt Op and custom Op for data preprocessing in RecordWriter",
                "displayName": "step_0_use_prebuilt_op_and_custom_op_for_data_preprocessing_in_recordwriter"
            },
            {
                "name": "Create a custom Numpy Op to rescale images in forward function",
                "displayName": "create_a_custom_numpy_op_to_rescale_images_in_forward_function"
            },
            {
                "name": "Define the RecordWriter with two ops Rescale and predefined ImageReader",
                "displayName": "define_the_recordwriter_with_two_ops_rescale_and_predefined_imagereader"
            },
            {
                "name": "Step 1: Use prebuilt and custom Ops for Pipeline",
                "displayName": "step_1_use_prebuilt_and_custom_ops_for_pipeline"
            },
            {
                "name": "Create a custom Resize Tensor op",
                "displayName": "create_a_custom_resize_tensor_op"
            },
            {
                "name": "We need init here as we want to add the size argument",
                "displayName": "we_need_init_here_as_we_want_to_add_the_size_argument"
            },
            {
                "name": "Create Pipeline with Resize op and Augmentation prebuilt op",
                "displayName": "create_pipeline_with_resize_op_and_augmentation_prebuilt_op"
            },
            {
                "name": "Augmentation2D automatically augment the dataset with rotation in the specified range",
                "displayName": "augmentation2d_automatically_augment_the_dataset_with_rotation_in_the_specified_range"
            },
            {
                "name": "Step 2: Use prebuilt and custom ops for Network",
                "displayName": "step_2_use_prebuilt_and_custom_ops_for_network"
            },
            {
                "name": "Create a custom TensorOp",
                "displayName": "create_a_custom_tensorop"
            },
            {
                "name": "Build the model and network",
                "displayName": "build_the_model_and_network"
            },
            {
                "name": "Step 3: Create the Estimator and train",
                "displayName": "step_3_create_the_estimator_and_train"
            },
            {
                "name": "Create the estimator",
                "displayName": "create_the_estimator"
            },
            {
                "name": "Launch the training",
                "displayName": "launch_the_training"
            }
        ]
    },
    {
        "name": "t04_pipeline_debug_benchmark.md",
        "displayName": " Tutorial 4: Pipeline debugging and benchmarking",
        "toc": [
            {
                "name": "Tutorial 4: Pipeline debugging and benchmarking",
                "displayName": "tutorial_4_pipeline_debugging_and_benchmarking"
            },
            {
                "name": "1 Define the pipeline same as tutorial 3",
                "displayName": "1_define_the_pipeline_same_as_tutorial_3"
            },
            {
                "name": "Create Rescale and Resize custom ops",
                "displayName": "create_rescale_and_resize_custom_ops"
            },
            {
                "name": "Load data",
                "displayName": "load_data"
            },
            {
                "name": "Create RecordWriter",
                "displayName": "create_recordwriter"
            },
            {
                "name": "Create Pipeline",
                "displayName": "create_pipeline"
            },
            {
                "name": "2 Access the pipeline results",
                "displayName": "2_access_the_pipeline_results"
            },
            {
                "name": "Use showresults by specifying the epoch mode and step batch",
                "displayName": "use_showresults_by_specifying_the_epoch_mode_and_step_batch"
            },
            {
                "name": "Isolate x and y from result",
                "displayName": "isolate_x_and_y_from_result"
            },
            {
                "name": "Display 4 examples of data after Pipeline",
                "displayName": "display_4_examples_of_data_after_pipeline"
            },
            {
                "name": "3 Benchmark pipeline speed",
                "displayName": "3_benchmark_pipeline_speed"
            },
            {
                "name": "You just have to specify the epoch mode and number of batches",
                "displayName": "you_just_have_to_specify_the_epoch_mode_and_number_of_batches"
            }
        ]
    },
    {
        "name": "t05_trace_debug_training.md",
        "displayName": " Tutorial 5: Trace  training control and debugging",
        "toc": [
            {
                "name": "Tutorial 5: Trace  training control and debugging",
                "displayName": "tutorial_5_trace__training_control_and_debugging"
            },
            {
                "name": "Import libraries",
                "displayName": "import_libraries"
            },
            {
                "name": "Using Trace to debug training loop",
                "displayName": "using_trace_to_debug_training_loop"
            },
            {
                "name": "1 Define the operation to test  pipeline and network",
                "displayName": "1_define_the_operation_to_test__pipeline_and_network"
            },
            {
                "name": "We define the scaling operation",
                "displayName": "we_define_the_scaling_operation"
            },
            {
                "name": "We load data create dictionnaries and prepare the Pipeline",
                "displayName": "we_load_data_create_dictionnaries_and_prepare_the_pipeline"
            },
            {
                "name": "We prepare the model and network which will use the scaling operation",
                "displayName": "we_prepare_the_model_and_network_which_will_use_the_scaling_operation"
            },
            {
                "name": "2 Define the trace",
                "displayName": "2_define_the_trace"
            },
            {
                "name": "We define a trace to show the predictions and test the scaling op",
                "displayName": "we_define_a_trace_to_show_the_predictions_and_test_the_scaling_op"
            },
            {
                "name": "We finally define the estimator specifying the trace argument For debugging we only use one epoch with one step",
                "displayName": "we_finally_define_the_estimator_specifying_the_trace_argument_for_debugging_we_only_use_one_epoch_with_one_step"
            },
            {
                "name": "We launch the training and can see what the scaled prediction looks like",
                "displayName": "we_launch_the_training_and_can_see_what_the_scaled_prediction_looks_like"
            }
        ]
    },
    {
        "name": "t06_TensorFilter_imbalanced_training.md",
        "displayName": " Tutorial 6:  Dealing with imbalanced dataset using TensorFilter",
        "toc": [
            {
                "name": "Tutorial 6:  Dealing with imbalanced dataset using TensorFilter",
                "displayName": "tutorial_6__dealing_with_imbalanced_dataset_using_tensorfilter"
            },
            {
                "name": "Step 0  Data preparation same as tutorial 1",
                "displayName": "step_0__data_preparation_same_as_tutorial_1"
            },
            {
                "name": "Import libraries",
                "displayName": "import_libraries"
            },
            {
                "name": "Load data and create dictionaries",
                "displayName": "load_data_and_create_dictionaries"
            },
            {
                "name": "Step 1  Customize your own Filter",
                "displayName": "step_1__customize_your_own_filter"
            },
            {
                "name": "We create our filter in forward function its just our condition",
                "displayName": "we_create_our_filter_in_forward_function_its_just_our_condition"
            },
            {
                "name": "We specify the filter in Pipeline ops list",
                "displayName": "we_specify_the_filter_in_pipeline_ops_list"
            },
            {
                "name": "Lets check our pipeline ops results with showresults",
                "displayName": "lets_check_our_pipeline_ops_results_with_showresults"
            },
            {
                "name": "or use a prebuilt ScalarFilter",
                "displayName": "or_use_a_prebuilt_scalarfilter"
            },
            {
                "name": "We specify the list of scalars to filter out and the probability to keep these scalars",
                "displayName": "we_specify_the_list_of_scalars_to_filter_out_and_the_probability_to_keep_these_scalars"
            },
            {
                "name": "Lets check our pipeline ops results with showresults",
                "displayName": "lets_check_our_pipeline_ops_results_with_showresults"
            }
        ]
    },
    {
        "name": "t07_expand_data_dimension.md",
        "displayName": " Tutorial 7: Expanding data dimension in RecordWriter and Pipeline",
        "toc": [
            {
                "name": "Tutorial 7: Expanding data dimension in RecordWriter and Pipeline",
                "displayName": "tutorial_7_expanding_data_dimension_in_recordwriter_and_pipeline"
            },
            {
                "name": "Import libraries",
                "displayName": "import_libraries"
            },
            {
                "name": "Step 1  RecordWriter: expand data dimension and write it to the disk",
                "displayName": "step_1__recordwriter_expand_data_dimension_and_write_it_to_the_disk"
            },
            {
                "name": "Load Mnist data",
                "displayName": "load_mnist_data"
            },
            {
                "name": "Create a custom Numpy op to sample 4 images from the corners of each image",
                "displayName": "create_a_custom_numpy_op_to_sample_4_images_from_the_corners_of_each_image"
            },
            {
                "name": "we sample 4 27x27 images from the corners:",
                "displayName": "we_sample_4_27x27_images_from_the_corners"
            },
            {
                "name": "We insert this custom op in the ops list of RecordWriter",
                "displayName": "we_insert_this_custom_op_in_the_ops_list_of_recordwriter"
            },
            {
                "name": "We have to specify expanddimsTrue to allow data dimension expansion",
                "displayName": "we_have_to_specify_expanddimstrue_to_allow_data_dimension_expansion"
            },
            {
                "name": "Step 2  Pipeline: expand dimension on the fly",
                "displayName": "step_2__pipeline_expand_dimension_on_the_fly"
            },
            {
                "name": "We create a custom op for random sampling",
                "displayName": "we_create_a_custom_op_for_random_sampling"
            },
            {
                "name": "We randomly select the topleft point of our image for each sample x and y coordinate",
                "displayName": "we_randomly_select_the_topleft_point_of_our_image_for_each_sample_x_and_y_coordinate"
            },
            {
                "name": "It cannot be greater than 8 as we will sample a 20x20 image from a 27x27 one",
                "displayName": "it_cannot_be_greater_than_8_as_we_will_sample_a_20x20_image_from_a_27x27_one"
            },
            {
                "name": "We sample two 20x20 images with x1y1 and x2y2 topleft corner",
                "displayName": "we_sample_two_20x20_images_with_x1y1_and_x2y2_topleft_corner"
            },
            {
                "name": "Create Pipeline with RandomSample op and expanddimsTrue",
                "displayName": "create_pipeline_with_randomsample_op_and_expanddimstrue"
            },
            {
                "name": "Step 3  Check pipeline results",
                "displayName": "step_3__check_pipeline_results"
            },
            {
                "name": "Lets check our pipeline ops results with showresults",
                "displayName": "lets_check_our_pipeline_ops_results_with_showresults"
            },
            {
                "name": "and visualize",
                "displayName": "and_visualize"
            },
            {
                "name": "Lets visualize the first 4 images keeping the order from our postpipeline data:",
                "displayName": "lets_visualize_the_first_4_images_keeping_the_order_from_our_postpipeline_data"
            }
        ]
    },
    {
        "name": "t08_scheduler_progressive_training.md",
        "displayName": " Tutorial 8: Changing hyperparameters during training with Scheduler",
        "toc": [
            {
                "name": "Tutorial 8: Changing hyperparameters during training with Scheduler",
                "displayName": "tutorial_8_changing_hyperparameters_during_training_with_scheduler"
            },
            {
                "name": "1 How to use Scheduler:",
                "displayName": "1_how_to_use_scheduler"
            },
            {
                "name": "2 Scheduler example:",
                "displayName": "2_scheduler_example"
            },
            {
                "name": "Step 0 Prepare data",
                "displayName": "step_0_prepare_data"
            },
            {
                "name": "We load MNIST dataset",
                "displayName": "we_load_mnist_dataset"
            },
            {
                "name": "Step 1 Prepare the Pipeline with the Schedulers",
                "displayName": "step_1_prepare_the_pipeline_with_the_schedulers"
            },
            {
                "name": "We create a scheduler for batchsize with the epochs at which it will change and corresponding values",
                "displayName": "we_create_a_scheduler_for_batchsize_with_the_epochs_at_which_it_will_change_and_corresponding_values"
            },
            {
                "name": "We create a scheduler for the Resize ops",
                "displayName": "we_create_a_scheduler_for_the_resize_ops"
            },
            {
                "name": "We create a scheduler for the different normalize ops we will want to use",
                "displayName": "we_create_a_scheduler_for_the_different_normalize_ops_we_will_want_to_use"
            },
            {
                "name": "In Pipeline we use the schedulers for batchsize and ops",
                "displayName": "in_pipeline_we_use_the_schedulers_for_batchsize_and_ops"
            },
            {
                "name": "Step 2 Prepare Network with the two models and a Scheduler",
                "displayName": "step_2_prepare_network_with_the_two_models_and_a_scheduler"
            },
            {
                "name": "We create two models and build them with their optimizer and loss",
                "displayName": "we_create_two_models_and_build_them_with_their_optimizer_and_loss"
            },
            {
                "name": "We create a Scheduler to indicate what model we want to train for each epoch",
                "displayName": "we_create_a_scheduler_to_indicate_what_model_we_want_to_train_for_each_epoch"
            },
            {
                "name": "We summarize the ops in Network using modelscheduler for ModelOp",
                "displayName": "we_summarize_the_ops_in_network_using_modelscheduler_for_modelop"
            },
            {
                "name": "Step 3 Build the Estimator and train",
                "displayName": "step_3_build_the_estimator_and_train"
            }
        ]
    },
    {
        "name": "t09_learning_rate_controller.md",
        "displayName": " Tutorial 9: Learning Rate Controller",
        "toc": [
            {
                "name": "Tutorial 9: Learning Rate Controller",
                "displayName": "tutorial_9_learning_rate_controller"
            },
            {
                "name": "Step 0 Preparation",
                "displayName": "step_0_preparation"
            },
            {
                "name": "Create a function to get Pipeline and Network",
                "displayName": "create_a_function_to_get_pipeline_and_network"
            },
            {
                "name": "step 1 Prepare data",
                "displayName": "step_1_prepare_data"
            },
            {
                "name": "step 2 Prepare model",
                "displayName": "step_2_prepare_model"
            },
            {
                "name": "Option 1 Customize the learning rate: stepwise control",
                "displayName": "option_1_customize_the_learning_rate_stepwise_control"
            },
            {
                "name": "Create a LR Scheduler with a custom schedulefn",
                "displayName": "create_a_lr_scheduler_with_a_custom_schedulefn"
            },
            {
                "name": "Create pipeline network and lrscheduler",
                "displayName": "create_pipeline_network_and_lrscheduler"
            },
            {
                "name": "In Estimator indicate in traces the LR Scheduler using LR Controller you also have to specify the modelname",
                "displayName": "in_estimator_indicate_in_traces_the_lr_scheduler_using_lr_controller_you_also_have_to_specify_the_modelname"
            },
            {
                "name": "Save the training history and train the model",
                "displayName": "save_the_training_history_and_train_the_model"
            },
            {
                "name": "Show the learning rates history for each step",
                "displayName": "show_the_learning_rates_history_for_each_step"
            },
            {
                "name": "Option 2  Customize the learning rate: epochwise control",
                "displayName": "option_2__customize_the_learning_rate_epochwise_control"
            },
            {
                "name": "We define our custom Scheduler in the same way as above",
                "displayName": "we_define_our_custom_scheduler_in_the_same_way_as_above"
            },
            {
                "name": "Create pipeline and network",
                "displayName": "create_pipeline_and_network"
            },
            {
                "name": "Here we now indicate epoch as schedulemode",
                "displayName": "here_we_now_indicate_epoch_as_schedulemode"
            },
            {
                "name": "Train and save history",
                "displayName": "train_and_save_history"
            },
            {
                "name": "Show the learning rate for each step: it changes only at an epoch level",
                "displayName": "show_the_learning_rate_for_each_step_it_changes_only_at_an_epoch_level"
            },
            {
                "name": "Option 3 Builtin Cyclic Learning Rate  example 1",
                "displayName": "option_3_builtin_cyclic_learning_rate__example_1"
            },
            {
                "name": "Create pipeline and network",
                "displayName": "create_pipeline_and_network"
            },
            {
                "name": "Directly use the prebuilt CyclicLRSchedule with a cosine decrease method and one cycle",
                "displayName": "directly_use_the_prebuilt_cycliclrschedule_with_a_cosine_decrease_method_and_one_cycle"
            },
            {
                "name": "Train and save history",
                "displayName": "train_and_save_history"
            },
            {
                "name": "Plot the learning rate for each step",
                "displayName": "plot_the_learning_rate_for_each_step"
            },
            {
                "name": "Option 3 Builtin Cyclic Learning Rate: example 2",
                "displayName": "option_3_builtin_cyclic_learning_rate_example_2"
            },
            {
                "name": "We create pipeline and network",
                "displayName": "we_create_pipeline_and_network"
            },
            {
                "name": "We specify numcycle and cyclemultiplier in CyclicLRSchedule",
                "displayName": "we_specify_numcycle_and_cyclemultiplier_in_cycliclrschedule"
            },
            {
                "name": "Train and save history",
                "displayName": "train_and_save_history"
            },
            {
                "name": "Plot the learning rate",
                "displayName": "plot_the_learning_rate"
            }
        ]
    },
    {
        "name": "t10_unpaired_dataset.md",
        "displayName": " Tutorial 10: Dataset with unpaired features",
        "toc": [
            {
                "name": "Tutorial 10: Dataset with unpaired features",
                "displayName": "tutorial_10_dataset_with_unpaired_features"
            },
            {
                "name": "Step 0  Data preparation and visualization",
                "displayName": "step_0__data_preparation_and_visualization"
            },
            {
                "name": "Use loaddata from our dataset API to load the dataset",
                "displayName": "use_loaddata_from_our_dataset_api_to_load_the_dataset"
            },
            {
                "name": "Lets take a look at the data by loading the csv file with all images path information",
                "displayName": "lets_take_a_look_at_the_data_by_loading_the_csv_file_with_all_images_path_information"
            },
            {
                "name": "We select one image of horse and one of zebra and plot them",
                "displayName": "we_select_one_image_of_horse_and_one_of_zebra_and_plot_them"
            },
            {
                "name": "Step 1  RecordWriter: read unpaired features using a tuple",
                "displayName": "step_1__recordwriter_read_unpaired_features_using_a_tuple"
            },
            {
                "name": "Create a RecordWriter with a tuple of two ops to pair images",
                "displayName": "create_a_recordwriter_with_a_tuple_of_two_ops_to_pair_images"
            },
            {
                "name": "We write the data to the disk using the write method",
                "displayName": "we_write_the_data_to_the_disk_using_the_write_method"
            }
        ]
    },
    {
        "name": "t11_interpretation.md",
        "displayName": " Tutorial 11: Interpretation",
        "toc": [
            {
                "name": "Tutorial 11: Interpretation",
                "displayName": "tutorial_11_interpretation"
            },
            {
                "name": "Download a sample model for demonstration",
                "displayName": "download_a_sample_model_for_demonstration"
            },
            {
                "name": "Interpretation with Bash",
                "displayName": "interpretation_with_bash"
            },
            {
                "name": "Interpretation with Python API",
                "displayName": "interpretation_with_python_api"
            },
            {
                "name": "Interpretation with Traces",
                "displayName": "interpretation_with_traces"
            }
        ]
    }
]